{
  
    
        "post0": {
            "title": "KERRY MATRIX",
            "content": "#collapse #IMPORTS import pandas as pd from matplotlib import pyplot as plt rtData = pd.read_csv(&#39;https://d14wlfuexuxgcm.cloudfront.net/covid/rt.csv&#39;) dailyData = pd.read_csv(&#39;https://covidtracking.com/api/v1/states/daily.csv&#39;) . . #collapse #SET VARIABLES today = &#39;2020-08-02&#39; week = &#39;2020-08-02/2020-07-26&#39; dateRange = &#39;20200802&#39; . . #collapse #KERRY LOCATIONS AND POPULATION DATA kerryLocations = pd.read_csv(&#39;../kerry.csv&#39;) kerryLocations.columns = map(str.lower, kerryLocations.columns) kerryCols=[&#39;state&#39;, &#39;population&#39;] kerryLocs = kerryLocations[kerryCols] print (&#39;Kerry Locations Information being loaded...&#39;) kerryLocs . . Kerry Locations Information being loaded... . state population . 0 AL† | 4,903,185 | . 1 AR† | 3,017,804 | . 2 CA* | 39,512,223 | . 3 FL* | 21,477,737 | . 4 GA | 10,617,423 | . 5 IA | 3,155,070 | . 6 IL | 12,671,821 | . 7 IN† | 6,732,219 | . 8 KS | 2,913,314 | . 9 MD | 6,045,680 | . 10 ME | 1,344,212 | . 11 MN | 5,639,632 | . 12 MO | 6,137,428 | . 13 MS† | 2,976,149 | . 14 NJ† | 8,882,190 | . 15 NY | 19,453,561 | . 16 OH | 11,689,100 | . 17 TN | 6,829,174 | . 18 TX* | 28,995,881 | . 19 VA | 8,535,519 | . 20 WA† | 7,614,893 | . 21 WI | 5,822,434 | . #collapse #rtlive data cleaning rtCleaned = rtData[rtData[&#39;date&#39;]==today] rtColumns = [&#39;date&#39;, &#39;region&#39;, &#39;mean&#39;] rtCleaned = rtCleaned[rtColumns] rtCleaned = rtCleaned.rename(columns = {&#39;region&#39;:&#39;state&#39;}) rtCleaned = rtCleaned.sort_values(&#39;state&#39;, ascending=True) #PRINT CLEANED DATA print (&#39;rtLive Data being loaded...&#39;) rtCleaned . . rtLive Data being loaded... . date state mean . 7999 2020-08-02 | AK | 1.044038 | . 3674 2020-08-02 | AL | 1.038194 | . 4947 2020-08-02 | AR | 1.032027 | . 7165 2020-08-02 | AZ | 0.868990 | . 7844 2020-08-02 | CA | 0.887025 | . 6379 2020-08-02 | CO | 0.998260 | . 952 2020-08-02 | CT | 0.981955 | . 2076 2020-08-02 | DC | 1.038579 | . 1594 2020-08-02 | DE | 0.946947 | . 2723 2020-08-02 | FL | 0.963125 | . 2560 2020-08-02 | GA | 0.951249 | . 8158 2020-08-02 | HI | 1.344259 | . 4631 2020-08-02 | IA | 0.987130 | . 6845 2020-08-02 | ID | 1.008629 | . 3997 2020-08-02 | IL | 1.079792 | . 3353 2020-08-02 | IN | 1.003324 | . 5740 2020-08-02 | KS | 1.064063 | . 2884 2020-08-02 | KY | 1.051189 | . 5106 2020-08-02 | LA | 0.911052 | . 629 2020-08-02 | MA | 1.045733 | . 1756 2020-08-02 | MD | 1.031470 | . 153 2020-08-02 | ME | 0.935425 | . 3519 2020-08-02 | MI | 0.990569 | . 4316 2020-08-02 | MN | 1.104105 | . 4791 2020-08-02 | MO | 1.162356 | . 4472 2020-08-02 | MS | 1.070742 | . 6691 2020-08-02 | MT | 1.044862 | . 2238 2020-08-02 | NC | 1.014149 | . 5262 2020-08-02 | ND | 1.091882 | . 5580 2020-08-02 | NE | 1.109083 | . 313 2020-08-02 | NH | 1.012778 | . 1276 2020-08-02 | NJ | 0.973840 | . 6217 2020-08-02 | NM | 0.926463 | . 7682 2020-08-02 | NV | 1.090898 | . 1115 2020-08-02 | NY | 0.962816 | . 3193 2020-08-02 | OH | 0.941024 | . 5898 2020-08-02 | OK | 0.995248 | . 7525 2020-08-02 | OR | 1.072128 | . 1437 2020-08-02 | PA | 0.977182 | . 792 2020-08-02 | RI | 1.141209 | . 2399 2020-08-02 | SC | 0.905029 | . 5419 2020-08-02 | SD | 1.119219 | . 3834 2020-08-02 | TN | 0.984245 | . 6060 2020-08-02 | TX | 0.956087 | . 7003 2020-08-02 | UT | 1.014811 | . 1916 2020-08-02 | VA | 1.095967 | . 474 2020-08-02 | VT | 0.838499 | . 7364 2020-08-02 | WA | 1.089897 | . 4155 2020-08-02 | WI | 0.917461 | . 3034 2020-08-02 | WV | 0.951932 | . 6535 2020-08-02 | WY | 1.006348 | . #collapse #DAILY DATA CLEANING dailyColumns = [&#39;date&#39;, &#39;state&#39;, &#39;death&#39;, &#39;positiveIncrease&#39;, &#39;totalTestResultsIncrease&#39;, &#39;deathIncrease&#39;] dailyData = dailyData[dailyColumns] dailyData = dailyData.sort_values(&#39;state&#39;, ascending=True) dailyCleaned = dailyData[dailyData[&#39;date&#39;].astype(str)==dateRange] dailyCleaned . . date state death positiveIncrease totalTestResultsIncrease deathIncrease . 168 20200802 | AK | 24.0 | 157 | 4457 | 0 | . 169 20200802 | AL | 1627.0 | 2095 | 8699 | 24 | . 170 20200802 | AR | 458.0 | 0 | 0 | -2 | . 171 20200802 | AS | 0.0 | 0 | 0 | 0 | . 172 20200802 | AZ | 3765.0 | 1465 | 7778 | 18 | . 173 20200802 | CA | 9356.0 | 9032 | 149388 | 132 | . 174 20200802 | CO | 1691.0 | 458 | 7169 | 0 | . 175 20200802 | CT | 4432.0 | 0 | 0 | 0 | . 176 20200802 | DC | 586.0 | 69 | 3411 | 1 | . 177 20200802 | DE | 585.0 | 72 | 2015 | 0 | . 178 20200802 | FL | 7206.0 | 7104 | 41554 | 62 | . 179 20200802 | GA | 3840.0 | 3165 | 28555 | 15 | . 180 20200802 | GU | 5.0 | 0 | 0 | 0 | . 181 20200802 | HI | 26.0 | 86 | 3390 | 0 | . 182 20200802 | IA | 876.0 | 516 | 5148 | 4 | . 183 20200802 | ID | 197.0 | 393 | 2426 | 8 | . 184 20200802 | IL | 7714.0 | 1467 | 38945 | 14 | . 185 20200802 | IN | 2975.0 | 735 | 10437 | 4 | . 186 20200802 | KS | 358.0 | 0 | 0 | 0 | . 187 20200802 | KY | 742.0 | 462 | 462 | 2 | . 188 20200802 | LA | 4007.0 | 3467 | 37197 | 58 | . 189 20200802 | MA | 8638.0 | 846 | 26110 | 29 | . 190 20200802 | MD | 3515.0 | 909 | 15432 | 9 | . 191 20200802 | ME | 123.0 | 21 | 2328 | 0 | . 192 20200802 | MI | 6457.0 | 429 | 25011 | 0 | . 193 20200802 | MN | 1654.0 | 759 | 12073 | 8 | . 194 20200802 | MO | 1253.0 | 582 | 5722 | 0 | . 195 20200802 | MP | 2.0 | 3 | 3 | 0 | . 196 20200802 | MS | 1703.0 | 672 | 672 | 10 | . 197 20200802 | MT | 61.0 | 112 | 2742 | 0 | . 198 20200802 | NC | 1969.0 | 1341 | 27098 | 5 | . 199 20200802 | ND | 95.0 | 0 | 0 | 0 | . 200 20200802 | NE | 332.0 | 180 | 1984 | 0 | . 201 20200802 | NH | 416.0 | 0 | 0 | 0 | . 202 20200802 | NJ | 15836.0 | 321 | 49180 | 6 | . 203 20200802 | NM | 651.0 | 196 | 7874 | 9 | . 204 20200802 | NV | 832.0 | 1131 | 7899 | 0 | . 205 20200802 | NY | 25170.0 | 531 | 58961 | 6 | . 206 20200802 | OH | 3529.0 | 944 | 24643 | 14 | . 207 20200802 | OK | 550.0 | 494 | 494 | 1 | . 208 20200802 | OR | 326.0 | 280 | 4041 | 1 | . 209 20200802 | PA | 7209.0 | 654 | 12247 | 5 | . 210 20200802 | PR | 230.0 | 539 | 539 | 5 | . 211 20200802 | RI | 1007.0 | 0 | 0 | 0 | . 212 20200802 | SC | 1777.0 | 1189 | 10388 | 26 | . 213 20200802 | SD | 135.0 | 88 | 1021 | 1 | . 214 20200802 | TN | 1073.0 | 1443 | 19445 | 6 | . 215 20200802 | TX | 6837.0 | 0 | 0 | 0 | . 216 20200802 | UT | 311.0 | 473 | 3456 | 1 | . 217 20200802 | VA | 2218.0 | 981 | 12665 | 3 | . 218 20200802 | VI | 8.0 | 0 | 0 | 0 | . 219 20200802 | VT | 57.0 | 5 | 1289 | 0 | . 220 20200802 | WA | 1592.0 | 1738 | 27874 | 28 | . 221 20200802 | WI | 955.0 | 932 | 9653 | 1 | . 222 20200802 | WV | 117.0 | 119 | 3988 | 1 | . 223 20200802 | WY | 26.0 | 39 | 39 | 0 | . #collapse #FILTER DATASETS TO KERRY LOCATIONS AND MERGE SETS INTO ONE TABLE startFile=pd.merge(kerryLocs.state, rtCleaned, on=[&#39;state&#39;]) print (&#39;Kerry File Building...&#39;) startFile . . Kerry File Building... . state date mean . 0 GA | 2020-08-02 | 0.951249 | . 1 IA | 2020-08-02 | 0.987130 | . 2 IL | 2020-08-02 | 1.079792 | . 3 KS | 2020-08-02 | 1.064063 | . 4 MD | 2020-08-02 | 1.031470 | . 5 ME | 2020-08-02 | 0.935425 | . 6 MN | 2020-08-02 | 1.104105 | . 7 MO | 2020-08-02 | 1.162356 | . 8 NY | 2020-08-02 | 0.962816 | . 9 OH | 2020-08-02 | 0.941024 | . 10 TN | 2020-08-02 | 0.984245 | . 11 VA | 2020-08-02 | 1.095967 | . 12 WI | 2020-08-02 | 0.917461 | . #collapse newData=pd.merge(startFile, dailyCleaned, on=[&#39;state&#39;]) newData=newData.rename(columns={&#39;date_x&#39;:&#39;date&#39;}) colss = [&#39;date&#39;, &#39;state&#39;, &#39;mean&#39;, &#39;death&#39;, &#39;positiveIncrease&#39;, &#39;totalTestResultsIncrease&#39;, &#39;deathIncrease&#39;] newData[colss] . . date state mean death positiveIncrease totalTestResultsIncrease deathIncrease . 0 2020-08-02 | GA | 0.951249 | 3840.0 | 3165 | 28555 | 15 | . 1 2020-08-02 | IA | 0.987130 | 876.0 | 516 | 5148 | 4 | . 2 2020-08-02 | IL | 1.079792 | 7714.0 | 1467 | 38945 | 14 | . 3 2020-08-02 | KS | 1.064063 | 358.0 | 0 | 0 | 0 | . 4 2020-08-02 | MD | 1.031470 | 3515.0 | 909 | 15432 | 9 | . 5 2020-08-02 | ME | 0.935425 | 123.0 | 21 | 2328 | 0 | . 6 2020-08-02 | MN | 1.104105 | 1654.0 | 759 | 12073 | 8 | . 7 2020-08-02 | MO | 1.162356 | 1253.0 | 582 | 5722 | 0 | . 8 2020-08-02 | NY | 0.962816 | 25170.0 | 531 | 58961 | 6 | . 9 2020-08-02 | OH | 0.941024 | 3529.0 | 944 | 24643 | 14 | . 10 2020-08-02 | TN | 0.984245 | 1073.0 | 1443 | 19445 | 6 | . 11 2020-08-02 | VA | 1.095967 | 2218.0 | 981 | 12665 | 3 | . 12 2020-08-02 | WI | 0.917461 | 955.0 | 932 | 9653 | 1 | . #collapse #ADDING CASES, TESTING, AND DEATHS TO DATA FILE dateRange=&#39;20200802&#39; cols = [&#39;date&#39;, &#39;state&#39;, &#39;death&#39;, &#39;positiveIncrease&#39;, &#39;totalTestResultsIncrease&#39;, &#39;deathIncrease&#39;] dailyData = dailyData[cols] dailyData = dailyData.sort_values(&#39;state&#39;, ascending=True) dailyData = dailyData[dailyData[&#39;date&#39;].astype(str)==dateRange] dailyData newData=pd.merge(startFile, dailyData, on=[&#39;state&#39;]) newData=newData.rename(columns={&#39;date_x&#39;:&#39;date&#39;}) colss = [&#39;date&#39;, &#39;state&#39;, &#39;mean&#39;, &#39;death&#39;, &#39;positiveIncrease&#39;, &#39;totalTestResultsIncrease&#39;, &#39;deathIncrease&#39;] newData[colss] . . date state mean death positiveIncrease totalTestResultsIncrease deathIncrease . 0 2020-08-02 | GA | 0.951249 | 3840.0 | 3165 | 28555 | 15 | . 1 2020-08-02 | IA | 0.987130 | 876.0 | 516 | 5148 | 4 | . 2 2020-08-02 | IL | 1.079792 | 7714.0 | 1467 | 38945 | 14 | . 3 2020-08-02 | KS | 1.064063 | 358.0 | 0 | 0 | 0 | . 4 2020-08-02 | MD | 1.031470 | 3515.0 | 909 | 15432 | 9 | . 5 2020-08-02 | ME | 0.935425 | 123.0 | 21 | 2328 | 0 | . 6 2020-08-02 | MN | 1.104105 | 1654.0 | 759 | 12073 | 8 | . 7 2020-08-02 | MO | 1.162356 | 1253.0 | 582 | 5722 | 0 | . 8 2020-08-02 | NY | 0.962816 | 25170.0 | 531 | 58961 | 6 | . 9 2020-08-02 | OH | 0.941024 | 3529.0 | 944 | 24643 | 14 | . 10 2020-08-02 | TN | 0.984245 | 1073.0 | 1443 | 19445 | 6 | . 11 2020-08-02 | VA | 1.095967 | 2218.0 | 981 | 12665 | 3 | . 12 2020-08-02 | WI | 0.917461 | 955.0 | 932 | 9653 | 1 | . #collapse startFile=pd.merge(kerryLocations.state, rtCleaned, on=[&#39;state&#39;]) print (&#39;Kerry File Building...&#39;) startFile . . Kerry File Building... . state date mean . 0 GA | 2020-08-02 | 0.951249 | . 1 IA | 2020-08-02 | 0.987130 | . 2 IL | 2020-08-02 | 1.079792 | . 3 KS | 2020-08-02 | 1.064063 | . 4 MD | 2020-08-02 | 1.031470 | . 5 ME | 2020-08-02 | 0.935425 | . 6 MN | 2020-08-02 | 1.104105 | . 7 MO | 2020-08-02 | 1.162356 | . 8 NY | 2020-08-02 | 0.962816 | . 9 OH | 2020-08-02 | 0.941024 | . 10 TN | 2020-08-02 | 0.984245 | . 11 VA | 2020-08-02 | 1.095967 | . 12 WI | 2020-08-02 | 0.917461 | . #collapse read = pd.read_csv(&#39;../us.csv&#39;) read.shape read.head() fee=[&#39;Kerry Locations&#39;, &#39;State&#39;, &#39;Population&#39;, &#39;SD Past&#39;] tre=read[fee] tre . . Kerry Locations State Population SD Past . 0 x | AK | 731,545 | 27.0 | . 1 Montgomery, AL | AL† | 4,903,185 | 29.0 | . 2 Hot Springs, AR | AR† | 3,017,804 | 26.0 | . 3 x | AZ* | 7,278,717 | 34.0 | . 4 Commerce, CA nMecca, CA nMontebello, CA nUnion... | CA* | 39,512,223 | 37.0 | . 5 x | CO* | 5,758,736 | 28.0 | . 6 x | CT† | 3,565,287 | 27.0 | . 7 x | DC | 705,749 | 57.0 | . 8 x | DE† | 973,764 | 28.0 | . 9 Lakeland, FL nPlant City, FL | FL* | 21,477,737 | 34.0 | . 10 Banks, GA nCalhoun, GA nRome, GA nSavannah, GA | GA | 10,617,423 | 30.0 | . 11 x | HI | 1,415,872 | 45.0 | . 12 Fredricksburg, IA nVinton, IA | IA | 3,155,070 | 25.0 | . 13 x | ID† | 1,787,065 | 26.0 | . 14 Carol Stream, IL nChicago, IL nElk Grove Villa... | IL | 12,671,821 | 27.0 | . 15 Evansville, IN nWest Bend, IN | IN† | 6,732,219 | 25.0 | . 16 New Century, KS | KS | 2,913,314 | 27.0 | . 17 x | KY | 4,467,673 | 26.0 | . 18 x | LA* | 4,648,794 | 37.0 | . 19 x | MA | 6,892,503 | 30.0 | . 20 Baltimore, MD | MD | 6,045,680 | 33.0 | . 21 Portland, ME | ME | 1,344,212 | 24.0 | . 22 x | MI* | 9,986,857 | 26.0 | . 23 Blue Earth, MN nOwatonna, MN nRochester, MN | MN | 5,639,632 | 29.0 | . 24 Affton, MO nGreenville, MO nNixa, MO nSpringfi... | MO | 6,137,428 | 26.0 | . 25 Vicksburg, MS | MS† | 2,976,149 | 30.0 | . 26 x | MT | 1,068,778 | 26.0 | . 27 x | NC† | 10,488,084 | 27.0 | . 28 x | ND | 762,062 | 26.0 | . 29 x | NE | 1,934,408 | 25.0 | . 30 x | NH | 1,359,711 | 24.0 | . 31 Clark, NJ nClark Savory, NJ | NJ† | 8,882,190 | 32.0 | . 32 x | NM* | 2,096,829 | 32.0 | . 33 x | NV* | 3,080,156 | 34.0 | . 34 North Rose, NY nNorwich, NY | NY | 19,453,561 | 39.0 | . 35 Byesville, OH | OH | 11,689,100 | 26.0 | . 36 x | OK | 3,956,971 | 26.0 | . 37 x | OR† | 4,217,737 | 30.0 | . 38 x | PA | 12,801,989 | 28.0 | . 39 x | RI | 1,059,361 | 26.0 | . 40 x | SC† | 5,148,714 | 28.0 | . 41 x | SD | 884,659 | 25.0 | . 42 Crossville, TN | TN | 6,829,174 | 26.0 | . 43 Forth Worth, TX | TX* | 28,995,881 | 36.0 | . 44 NaN | UT | 3,205,958 | 28.0 | . 45 Harrisonburg, VA | VA | 8,535,519 | 30.0 | . 46 NaN | VT | 623,989 | 25.0 | . 47 Seattle, WA nSummer, WA | WA† | 7,614,893 | 30.0 | . 48 Beloit, WI nJackson, WI nManitowoc, WI nOwen, ... | WI | 5,822,434 | 26.0 | . 49 x | WV | 1,792,147 | 26.0 | . 50 x | WY† | 578,759 | 26.0 | . 51 NaN | NaN | NaN | NaN | . 52 NaN | NaN | NaN | NaN | . 53 NaN | NaN | NaN | NaN | . #collapse plt.title(&quot;Canada Matrix Chart&quot;) plt.xlabel(&quot;State&quot;) plt.ylabel(&quot;SD Past&quot;) x = tre[&quot;SD Past&quot;] y = tre[&quot;State&quot;] plt.plot(x,y) . . TypeError Traceback (most recent call last) &lt;ipython-input-13-72d3c6c95b5a&gt; in &lt;module&gt; 6 y = tre[&#34;State&#34;] 7 -&gt; 8 plt.plot(x,y) C: Users anaconda3 envs USAcovidMAP lib site-packages matplotlib pyplot.py in plot(scalex, scaley, data, *args, **kwargs) 2759 @docstring.copy(Axes.plot) 2760 def plot(*args, scalex=True, scaley=True, data=None, **kwargs): -&gt; 2761 return gca().plot( 2762 *args, scalex=scalex, scaley=scaley, **({&#34;data&#34;: data} if data 2763 is not None else {}), **kwargs) C: Users anaconda3 envs USAcovidMAP lib site-packages matplotlib axes _axes.py in plot(self, scalex, scaley, data, *args, **kwargs) 1645 &#34;&#34;&#34; 1646 kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D) -&gt; 1647 lines = [*self._get_lines(*args, data=data, **kwargs)] 1648 for line in lines: 1649 self.add_line(line) C: Users anaconda3 envs USAcovidMAP lib site-packages matplotlib axes _base.py in __call__(self, *args, **kwargs) 214 this += args[0], 215 args = args[1:] --&gt; 216 yield from self._plot_args(this, kwargs) 217 218 def get_next_color(self): C: Users anaconda3 envs USAcovidMAP lib site-packages matplotlib axes _base.py in _plot_args(self, tup, kwargs) 337 self.axes.xaxis.update_units(x) 338 if self.axes.yaxis is not None: --&gt; 339 self.axes.yaxis.update_units(y) 340 341 if x.shape[0] != y.shape[0]: C: Users anaconda3 envs USAcovidMAP lib site-packages matplotlib axis.py in update_units(self, data) 1514 neednew = self.converter != converter 1515 self.converter = converter -&gt; 1516 default = self.converter.default_units(data, self) 1517 if default is not None and self.units is None: 1518 self.set_units(default) C: Users anaconda3 envs USAcovidMAP lib site-packages matplotlib category.py in default_units(data, axis) 105 # the conversion call stack is default_units -&gt; axis_info -&gt; convert 106 if axis.units is None: --&gt; 107 axis.set_units(UnitData(data)) 108 else: 109 axis.units.update(data) C: Users anaconda3 envs USAcovidMAP lib site-packages matplotlib category.py in __init__(self, data) 173 self._counter = itertools.count() 174 if data is not None: --&gt; 175 self.update(data) 176 177 @staticmethod C: Users anaconda3 envs USAcovidMAP lib site-packages matplotlib category.py in update(self, data) 210 for val in OrderedDict.fromkeys(data): 211 # OrderedDict just iterates over unique values in data. --&gt; 212 cbook._check_isinstance((str, bytes), value=val) 213 if convertible: 214 # this will only be called so long as convertible is True. C: Users anaconda3 envs USAcovidMAP lib site-packages matplotlib cbook __init__.py in _check_isinstance(_types, **kwargs) 2121 for k, v in kwargs.items(): 2122 if not isinstance(v, types): -&gt; 2123 raise TypeError( 2124 &#34;{!r} must be an instance of {}, not a {}&#34;.format( 2125 k, TypeError: &#39;value&#39; must be an instance of str or bytes, not a float . #collapse mer = pd.merge(rtChanged, dailyData, on=[&#39;state&#39;]) . . NameError Traceback (most recent call last) &lt;ipython-input-14-7f18e2646e9e&gt; in &lt;module&gt; 1 #collapse -&gt; 2 mer = pd.merge(rtChanged, dailyData, on=[&#39;state&#39;]) NameError: name &#39;rtChanged&#39; is not defined . #collapse mer . . NameError Traceback (most recent call last) &lt;ipython-input-15-b5fdaede45b3&gt; in &lt;module&gt; 1 #collapse -&gt; 2 mer NameError: name &#39;mer&#39; is not defined . #collapse meg = pd.merge(kerryLocations, mer, on=&#39;state&#39;) meg = meg.rename(columns={&#39;date_x&#39;:&#39;date&#39;}) coll = [&#39;state&#39;, &#39;mean&#39;, &#39;death&#39;, &#39;positiveIncrease&#39;, &#39;totalTestResultsIncrease&#39;, &#39;deathIncrease&#39;] mew = meg[coll] print (&#39;Kerry Locations&#39;) print (&#39;Matrix Report&#39;) mew . . NameError Traceback (most recent call last) &lt;ipython-input-16-3ac346b02f87&gt; in &lt;module&gt; 1 #collapse -&gt; 2 meg = pd.merge(kerryLocations, mer, on=&#39;state&#39;) 3 meg = meg.rename(columns={&#39;date_x&#39;:&#39;date&#39;}) 4 coll = [&#39;state&#39;, &#39;mean&#39;, &#39;death&#39;, &#39;positiveIncrease&#39;, &#39;totalTestResultsIncrease&#39;, &#39;deathIncrease&#39;] 5 mew = meg[coll] NameError: name &#39;mer&#39; is not defined . #collapse #chart over time fig, ax = plt.subplots(figsize=(10,5)) dailyData.death.plot(c=&quot;g&quot;, label=&quot;Test-adjusted&quot;) dailyData.positiveIncrease.plot(c=&quot;g&quot;, alpha=.5, label=&quot;Test-adjusted (raw)&quot;, style=&quot;--&quot;) dailyData.deathIncrease.plot(c=&quot;b&quot;, label=&quot;Infections&quot;) fig.set_facecolor(&#39;w&#39;) ax.legend(); . .",
            "url": "https://richcastro82.github.io/Matrix/jupyter/2020/08/05/USM.html",
            "relUrl": "/jupyter/2020/08/05/USM.html",
            "date": " • Aug 5, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "toc: false | comments: true | image: images/US_case_count.png | hide: false | search_exclude: false | categories: geospatial | author: Shantam Raj | badges: true | . Today we will make our first geospatial map from the article Coronavirus in the U.S.: Latest Map and Case Count which looks like the folowing - . import geopandas as gpd import altair as alt import pandas as pd alt.renderers.set_embed_options(actions=False) # Shapefiles from us census state_shpfile = &#39;./shapes/cb_2019_us_state_20m&#39; county_shpfile = &#39;./shapes/cb_2019_us_county_20m&#39; states = gpd.read_file(state_shpfile) county = gpd.read_file(county_shpfile) # Adding longitude and latitude in state data states[&#39;lon&#39;] = states[&#39;geometry&#39;].centroid.x states[&#39;lat&#39;] = states[&#39;geometry&#39;].centroid.y # Adding longitude and latitude in state data county[&#39;lon&#39;] = county[&#39;geometry&#39;].centroid.x county[&#39;lat&#39;] = county[&#39;geometry&#39;].centroid.y . # NYT dataset county_url = &#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv&#39; cdf = pd.read_csv(county_url) . cdf[cdf[&#39;fips&#39;].isnull() == True].groupby([&#39;county&#39;]).sum() . fips cases deaths . county . Joplin 0.0 | 329 | 4 | . Kansas City 0.0 | 85094 | 1700 | . New York City 0.0 | 15615980 | 1528538 | . Unknown 0.0 | 885104 | 41064 | . #hide_output cdf[cdf[&#39;fips&#39;].isnull() == True].groupby([&#39;county&#39;, &#39;state&#39;]).sum() . NYT publishes the data for New York City in a different way by combining the results of the 5 boroughs that comprise it. So we will combine them too and add a new row in the dataset with a custom fips of 1. Let&#39;s start by making this change in the raw NYT dataset itself. . cdf.loc[cdf[&#39;county&#39;] == &#39;New York City&#39;,&#39;fips&#39;] = 1 cdf[cdf[&#39;county&#39;] == &#39;New York City&#39;] . date county state fips cases deaths . 416 2020-03-01 | New York City | New York | 1.0 | 1 | 0 | . 448 2020-03-02 | New York City | New York | 1.0 | 1 | 0 | . 482 2020-03-03 | New York City | New York | 1.0 | 2 | 0 | . 518 2020-03-04 | New York City | New York | 1.0 | 2 | 0 | . 565 2020-03-05 | New York City | New York | 1.0 | 4 | 0 | . ... ... | ... | ... | ... | ... | ... | . 262876 2020-06-23 | New York City | New York | 1.0 | 217803 | 21817 | . 265930 2020-06-24 | New York City | New York | 1.0 | 218089 | 21838 | . 268988 2020-06-25 | New York City | New York | 1.0 | 218429 | 21856 | . 272054 2020-06-26 | New York City | New York | 1.0 | 218799 | 21893 | . 275123 2020-06-27 | New York City | New York | 1.0 | 219157 | 21913 | . 119 rows × 6 columns . # collapse latest_cases = cdf.groupby(&#39;fips&#39;, as_index=False).agg({&#39;county&#39;: &#39;last&#39;, &#39;date&#39;: &#39;last&#39;, &#39;state&#39;: &#39;last&#39;, &#39;cases&#39;: &#39;last&#39;, &#39;deaths&#39;: &#39;last&#39;}) latest_cases . . fips county date state cases deaths . 0 1.0 | New York City | 2020-06-27 | New York | 219157 | 21913 | . 1 1001.0 | Autauga | 2020-06-27 | Alabama | 498 | 12 | . 2 1003.0 | Baldwin | 2020-06-27 | Alabama | 555 | 10 | . 3 1005.0 | Barbour | 2020-06-27 | Alabama | 317 | 1 | . 4 1007.0 | Bibb | 2020-06-27 | Alabama | 161 | 1 | . ... ... | ... | ... | ... | ... | ... | . 3038 56037.0 | Sweetwater | 2020-06-27 | Wyoming | 81 | 0 | . 3039 56039.0 | Teton | 2020-06-27 | Wyoming | 119 | 1 | . 3040 56041.0 | Uinta | 2020-06-27 | Wyoming | 167 | 0 | . 3041 56043.0 | Washakie | 2020-06-27 | Wyoming | 38 | 5 | . 3042 56045.0 | Weston | 2020-06-27 | Wyoming | 1 | 0 | . 3043 rows × 6 columns . Now we have to make the changes in our shapefile too. For that we need to **dissolve** the 5 buroughs into one single geospatial entity. . #New York City fips = 36005&#39;, &#39;36047&#39;, &#39;36061&#39;, &#39;36081&#39;, &#39;36085 which corresponds to New York, Kings, Queens, Bronx and Richmond spatial_nyc = county[county[&#39;GEOID&#39;].isin([&#39;36005&#39;, &#39;36047&#39;, &#39;36061&#39;, &#39;36081&#39;, &#39;36085&#39;])] . combined_nyc = spatial_nyc.dissolve(by=&#39;STATEFP&#39;) alt.Chart(spatial_nyc).mark_geoshape(stroke=&#39;white&#39;, strokeWidth=3).encode() | alt.Chart(combined_nyc).mark_geoshape(stroke=&#39;white&#39;, strokeWidth=3).encode() . agg_nyc_data = spatial_nyc.dissolve(by=&#39;STATEFP&#39;).reset_index() agg_nyc_data[&#39;GEOID&#39;] = &#39;1&#39; agg_nyc_data[&#39;fips&#39;] = 1 agg_nyc_data[&#39;lon&#39;] = agg_nyc_data[&#39;geometry&#39;].centroid.x agg_nyc_data[&#39;lat&#39;] = agg_nyc_data[&#39;geometry&#39;].centroid.y . agg_nyc_data . STATEFP geometry COUNTYFP COUNTYNS AFFGEOID GEOID NAME LSAD ALAND AWATER lon lat fips . 0 36 | POLYGON ((-74.24921 40.54506, -74.21684 40.558... | 061 | 00974129 | 0500000US36061 | 1 | New York | 06 | 58690498 | 28541727 | -73.927011 | 40.695278 | 1 | . # hide_output county_nyc = gpd.GeoDataFrame(pd.concat([county, agg_nyc_data], ignore_index=True)) county_nyc[&#39;fips&#39;] = county_nyc[&#39;GEOID&#39;] county_nyc[&#39;fips&#39;] = county_nyc[&#39;fips&#39;].astype(&#39;int&#39;) county_nyc # generate FIPS in the shapefile itself by combining STATEFP and COUNTYFP #county2[&#39;STATEFP&#39;] + county2[&#39;COUNTYFP&#39;] #latest_cases[&#39;fips&#39;] = latest_cases[&#39;fips&#39;].astype(&#39;int&#39;) . latest_cases[&#39;fips&#39;].isin(county_nyc[&#39;fips&#39;]).value_counts() . True 3043 Name: fips, dtype: int64 . latest_cases[latest_cases[&#39;county&#39;] == &#39;New York City&#39;] . fips county date state cases deaths . 0 1.0 | New York City | 2020-06-27 | New York | 219157 | 21913 | . county_nyc[county_nyc[&#39;fips&#39;] == 1] . STATEFP COUNTYFP COUNTYNS AFFGEOID GEOID NAME LSAD ALAND AWATER geometry lon lat fips . 3220 36 | 061 | 00974129 | 0500000US36061 | 1 | New York | 06 | 58690498 | 28541727 | POLYGON ((-74.24921 40.54506, -74.21684 40.558... | -73.927011 | 40.695278 | 1 | . # collapse latest_cases_w_fips = county_nyc.merge(latest_cases, how=&#39;left&#39;, on=&#39;fips&#39;) circle_selection = alt.selection_single(on=&#39;mouseover&#39;, empty=&#39;none&#39;) circles = alt.Chart(latest_cases_w_fips).mark_point(fillOpacity=0.2, fill=&#39;red&#39;, strokeOpacity=1, color=&#39;red&#39;, strokeWidth=1).encode( latitude=&quot;lat:Q&quot;, longitude=&quot;lon:Q&quot;, size=alt.Size(&#39;cases:Q&#39;, scale=alt.Scale(domain=[0, 7000],),legend=alt.Legend(title=&quot;Cases&quot;)), tooltip=[&#39;county:N&#39;, &#39;cases:Q&#39;, &#39;deaths:Q&#39;], color = alt.condition(circle_selection, alt.value(&#39;black&#39;), alt.value(&#39;red&#39;)) ).project( type=&#39;albersUsa&#39; ).properties( width=1000, height=700 ).add_selection( circle_selection ) state = alt.Chart(states).mark_geoshape(fill=&#39;#ededed&#39;, stroke=&#39;white&#39;).encode( ).project( type=&#39;albersUsa&#39; ) state_text = state.mark_text().transform_filter(alt.datum.NAME != &#39;Puerto Rico&#39;).encode( longitude=&#39;lon:Q&#39;, latitude=&#39;lat:Q&#39;, text=&#39;NAME&#39;, ).project( type=&#39;albersUsa&#39; ) . . (state+circles+state_text).configure_view(strokeWidth=0) .",
            "url": "https://richcastro82.github.io/Matrix/2020/06/12/US-case-counts-geospatial.html",
            "relUrl": "/2020/06/12/US-case-counts-geospatial.html",
            "date": " • Jun 12, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://richcastro82.github.io/Matrix/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://richcastro82.github.io/Matrix/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}